
# Model Evaluation Report


---

## Metrics

- **ROC AUC:** 0.9371  
- **Threshold:** 0.4120  

---

## Classification Report

              precision    recall  f1-score   support

           0       0.80      0.78      0.79        88
           1       0.87      0.88      0.87       141

    accuracy                           0.84       229
   macro avg       0.83      0.83      0.83       229
weighted avg       0.84      0.84      0.84       229



---

## Confusion Matrix

![Confusion Matrix](reports\confusion_matrix.png)

---

## ROC Curve

![ROC Curve](reports\roc_curve.png)

---

## Precision-Recall Curve

![Precision-Recall Curve](reports\pr_curve.png)
